"""
tfidf

vetoriza os textos de um partido e pontua com uso de TF-IDF para futura classificação automática de tema.
o partido usado no exemplo é o PT.
há a opção de fazer a análise com a raiz das palavras (stems).
no fim, imprime as 10 palavras mais pontuadas por data.
"""


import operator
import string
from nltk.corpus import stopwords
import pandas as pd
from nltk.stem.snowball import PortugueseStemmer
from sklearn.feature_extraction.text import TfidfVectorizer

pd.set_option('display.max_row', 1000)
pd.set_option('display.max_columns', 50)

df = pd.DataFrame(pd.read_csv('todos_textos.csv',
                               dtype=str,
                               keep_default_na=False)
                  )

df = df.drop(df.columns[[0, 1, 2, 4, 5, 6, 7, 9, 11]], axis=1)

tradutor = str.maketrans({key: None for key in string.punctuation})

stop_words = stopwords.words('portuguese')
stop_words_custom = ['sr', 'srª', 'srªs', 'srs', 'senador', 'senadora',
                     'presidente', 'presidenta', 'senadores', 'senadoras',
                     'exº', 'exª', 'br', 'brs', 'aqui', 'brasil']
stop_words.extend(stop_words_custom)

df = df.loc[df['Partido'] == 'PT']
df = df.drop('Partido', 1)
df = df.groupby(['Data'])['Texto'].apply(' '.join).reset_index()

df['Data'] = pd.to_datetime(df['Data'], format='%d/%m/%Y')
df = df.sort_values(by=['Data'])

st = PortugueseStemmer()

grandic = {}
datas = []
for data in df['Data']:
    texto = df.loc[df['Data'] == data.date()]['Texto']
    texto = texto.str.cat(sep=' ')
    bow = texto.translate(tradutor).lower().split()
    clean = [word.replace('“', '').replace('”', '') for word in bow
             if word not in stop_words and len(word) > 1]
#    stemmed = [st.stem(w) for w in clean]
#    grandic[data] = ' '.join(stemmed)
    grandic[data] = ' '.join(clean)
    datas.append(data)
    
corpus = grandic.values()

vocab = set()
for doc in corpus:
    vocab.update(doc.split())

vocab = list(vocab)
index = {w: idx for idx, w in enumerate(vocab)}

tfidf = TfidfVectorizer(vocabulary=vocab)

tfidf.fit(corpus)
tfidf.transform(corpus)

tabela = {}

for doc in corpus:
    pontos = {}
    X = tfidf.transform([doc])
    for w in doc.split():
        pontos[w] = X[0, tfidf.vocabulary_[w]]
    ordenado = sorted(pontos.items(), key=operator.itemgetter(1), reverse=True)
    k = list(grandic.keys())[list(grandic.values()).index(doc)]
    tabela[k] = ordenado

for data in datas:
    print(str(data.date())+': '+str(tabela[data][:10]))
